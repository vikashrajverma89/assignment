{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76eae7f6-2cda-41ae-883a-2fb7145df74d",
   "metadata": {},
   "source": [
    "## Q1. What is Bayes' theorem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22f1431-bedf-44d2-b7ff-b3062b921d60",
   "metadata": {},
   "source": [
    "Bayes' theorem, named after the Reverend Thomas Bayes, is a fundamental concept in probability theory and statistics. It provides a way to update the probability of a hypothesis based on new evidence or information\n",
    "\n",
    "Pr(A/B)=Pr(A)* Pr(B/A) / Pr(B)\n",
    "\n",
    "- P(A∣B) is the probability of hypothesis \n",
    "- A given the evidence B,\n",
    "- P(B∣A) is the probability of evidence B given the hypothesis \n",
    "- A,\n",
    "- P(A) is the prior probability of hypothesis A,\n",
    "- P(B) is the probability of the evidence B.\n",
    "\n",
    "In words, Bayes' theorem states that the probability of a hypothesis given some observed evidence is proportional to the product of the prior probability of the hypothesis and the likelihood of the evidence given that hypothesis, divided by the overall probability of the evidence.\n",
    "\n",
    "This theorem is widely used in various fields, including statistics, machine learning, and artificial intelligence, for tasks such as Bayesian inference, updating beliefs, and making predictions based on new information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248cd415-60e5-4010-99d3-9126481f560b",
   "metadata": {},
   "source": [
    "## Q2. What is the formula for Bayes' theorem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b464074-b626-4aed-8c01-ae5193838c49",
   "metadata": {},
   "source": [
    "Pr(A/B)=Pr(A)* Pr(B/A) / Pr(B)\n",
    "\n",
    "- P(A∣B) is the probability of hypothesis \n",
    "- A given the evidence B,\n",
    "- P(B∣A) is the probability of evidence B given the hypothesis A,\n",
    "- P(A) is the prior probability of hypothesis A,\n",
    "- P(B) is the probability of the evidence B."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb13ce57-f41b-45ac-aa10-fe3c44f4eb48",
   "metadata": {},
   "source": [
    "## Q3. How is Bayes' theorem used in practice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b77e7221-1321-4e87-bafb-7dc83e4f4aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.naive_bayes import GaussianNB\n",
    "#gnb=GaussianNB()\n",
    "#training the model\n",
    "#gnb.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431c8775-a92e-4627-8cd7-3f8b4bed53a4",
   "metadata": {},
   "source": [
    "Bayes' theorem is used in practice for a variety of purposes in fields such as statistics, machine learning, and artificial intelligence. Here are some common applications:\n",
    "\n",
    "- Bayesian Inference: Bayes' theorem is fundamental to Bayesian inference, a statistical approach that updates beliefs or probabilities based on new evidence. It is used to calculate the posterior probability of a hypothesis given observed data, combining prior knowledge and new information.\n",
    "\n",
    "- Medical Diagnosis: In medical diagnosis, Bayes' theorem can be applied to update the probability of a disease given observed symptoms. It helps doctors make more accurate diagnoses by incorporating both prior knowledge (prevalence of the disease) and the likelihood of symptoms given the presence or absence of the disease.\n",
    "\n",
    "- Spam Filtering: Bayes' theorem is used in email spam filters to classify emails as spam or not spam. The algorithm considers the prior probability of certain words or phrases appearing in spam or non-spam emails and updates these probabilities based on new examples.\n",
    "\n",
    "- Machine Learning: In machine learning, Bayesian methods are used for model training and inference. Bayesian models are particularly useful when dealing with uncertainty, and Bayes' theorem helps update the model parameters as new data becomes available.\n",
    "\n",
    "- A/B Testing: Bayes' theorem is applied in A/B testing scenarios to assess the probability that a change in a product or website leads to a desired outcome. It helps in making decisions about whether to adopt a new feature based on observed user behavior.\n",
    "\n",
    "- Fault Diagnosis: In engineering and reliability analysis, Bayes' theorem can be used to assess the probability of a particular component or system failure given observed data on performance and maintenance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0672006c-d7e5-4ca6-9828-7561075a76d4",
   "metadata": {},
   "source": [
    "## Q4. What is the relationship between Bayes' theorem and conditional probability?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5cdb74-323d-4466-9976-9af2a1ae2f4b",
   "metadata": {},
   "source": [
    "Bayes' theorem is closely related to conditional probability, and it provides a way to update conditional probabilities based on new evidence. The relationship can be understood by examining the components of Bayes' theorem in terms of conditional probabilities.\n",
    "Bayes' theorem is expressed as:\n",
    "\n",
    "P(A∣B)= P(A)* P(B/A)/P(B)\n",
    "So, Bayes' theorem essentially relates the conditional probability \n",
    "\n",
    "P(A∣B) to the conditional probability P(B∣A), the prior probability P(A), and the overall probability P(B).\n",
    "In summary, Bayes' theorem is a formula that enables the updating of conditional probabilities by incorporating prior knowledge and new evidence. It provides a framework for reasoning about uncertainty and making informed decisions based on observed data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0ebfb0-9beb-4460-9b60-8f132817515a",
   "metadata": {},
   "source": [
    "## Q5. How do you choose which type of Naive Bayes classifier to use for any given problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c27620a-0464-4b3b-937e-e07fa3b33df7",
   "metadata": {},
   "source": [
    "The choice of which type of Naive Bayes classifier to use depends on the nature of the features in your dataset and the assumptions that are reasonable for your specific problem. The three main types of Naive Bayes classifiers are:\n",
    "\n",
    "1. **Gaussian Naive Bayes:**\n",
    "   - Assumes that the features follow a Gaussian (normal) distribution.\n",
    "   - Suitable for continuous data.\n",
    "   - Each feature is assumed to be normally distributed within each class.\n",
    "\n",
    "2. **Multinomial Naive Bayes:**\n",
    "   - Assumes that the features are discrete and represent counts (e.g., word counts in a document).\n",
    "   - Suitable for features that describe the frequency with which certain events occur.\n",
    "\n",
    "3. **Bernoulli Naive Bayes:**\n",
    "   - Assumes that the features are binary (0 or 1).\n",
    "   - Suitable for binary or boolean features.\n",
    "\n",
    "The choice among these classifiers depends on the characteristics of your dataset. Here are some general guidelines:\n",
    "\n",
    "- **Gaussian Naive Bayes:**\n",
    "  - Use when the features are continuous and can be reasonably assumed to follow a normal distribution.\n",
    "  - Commonly used in tasks like text classification when word frequencies are transformed into real-valued features using methods like TF-IDF.\n",
    "\n",
    "- **Multinomial Naive Bayes:**\n",
    "  - Use when dealing with discrete features, especially in text classification where word counts or term frequencies are important.\n",
    "  - Commonly used for document classification tasks.\n",
    "\n",
    "- **Bernoulli Naive Bayes:**\n",
    "  - Use when dealing with binary features, such as presence or absence of certain words.\n",
    "  - Suitable for problems where the data is naturally binary or can be discretized into binary form.\n",
    "\n",
    "It's important to note that the \"naive\" assumption in Naive Bayes is that features are conditionally independent given the class label. This assumption simplifies the model and, despite its simplicity, Naive Bayes classifiers often perform well in practice, especially when the independence assumption holds or doesn't significantly impact the classification accuracy for the given problem.\n",
    "\n",
    "In practice, it's often a good idea to try different Naive Bayes classifiers on your dataset and evaluate their performance to determine which one works best for your specific problem. Cross-validation and performance metrics such as accuracy, precision, recall, and F1-score can help you assess the effectiveness of different classifiers on your data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891ffc93-1f44-450e-a37e-0a3920fc7509",
   "metadata": {},
   "source": [
    "## Q6. Assignment:You have a dataset with two features, X1 and X2, and two possible classes, A and B. You want to use Naive Bayes to classify a new instance with features X1 = 3 and X2 = 4. The following table shows the frequency of each feature value for each class:  \n",
    "Class X1=1 X1=2 X1=3 X2=1 X2=2 X2=3 X2=4\n",
    "A 3 3 4 4 3 3 3\n",
    "B 2 2 1 2 2 2 3\n",
    "Assuming equal prior probabilities for each class, which class would Naive Bayes predict the new instance\n",
    "to belong to?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71ef4c6-4073-443e-8883-6eb15d81f778",
   "metadata": {},
   "source": [
    "\n",
    "To classify the new instance with features X1=3 and X2=4 using Naive Bayes, we can calculate the likelihoods for each class and then use Bayes' theorem to determine the posterior probabilities. Given that the prior probabilities are equal for both classes (because there is no information about class frequencies), we can focus on the likelihoods.\n",
    "Let \n",
    "A represent class A and B represent class B.\n",
    "\n",
    "The likelihood for each class is the product of the probabilities of each feature given the class\n",
    "P(X1=3∣A)×P(X2=4∣A)×P(A)\n",
    "P(X1=3∣B)×P(X2=4∣B)×P(B)\n",
    "\n",
    "Using the provided table\n",
    "P(X1=3∣A)= 4/10\n",
    "P(X2=4∣A)= 3/10\n",
    "P(X1=3∣B)= 1/5\n",
    "P(X2=4∣B)= 3/5\n",
    "\n",
    "Since the prior probabilities \n",
    "P(A) and P(B) are assumed to be equal, they cancel out in the comparison.\n",
    "\n",
    "Now, calculate the likelihood for each class:\n",
    "Likelihood for A= 4/10 * 3/10 =12/100\n",
    "Likelihood for B= 1/5 * 3/5 = 3/25\n",
    "Since 12/100> 3/25, the naive bayes classifier would predict that the new instance with X1 = 3 and X2 =4 belongs to class A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12fc277-7b82-47c3-a2da-478b7c86141f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
