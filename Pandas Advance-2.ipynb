{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37a110c1-840e-4a69-8a75-8c79bd554d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consider following code to answer further questions:\n",
    "import pandas as pd\n",
    "\n",
    "# Define lists for course names and durations\n",
    "course_name = ['Data Science', 'Machine Learning', 'Big Data', 'Data Engineer']\n",
    "duration = [2, 3, 6, 4]\n",
    "\n",
    "# Create a DataFrame using the provided data\n",
    "df = pd.DataFrame(data={'course_name': course_name, 'duration': duration})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6781109e-bfa5-4ed7-8d71-217395bce119",
   "metadata": {},
   "source": [
    "## Q1. Write a code to print the data present in the second row of the dataframe, df."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef49fb1-a0a9-4d34-ae54-f934fbe8b340",
   "metadata": {},
   "source": [
    "# \n",
    "Certainly! You can use the .iloc indexer to locate and retrieve data based on integer-location. The second row has an index of 1 (remember, Python uses 0-based indexing), so you can use df.iloc[1] to print the data present in the second row. Here's the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b05db4d-a2b4-4ef5-915c-16cb0fbbe63f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "course_name    Machine Learning\n",
      "duration                      3\n",
      "Name: 1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.iloc[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f5306c0-0919-4b6f-9292-7b73ef7023b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>course_name</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Big Data</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        course_name  duration\n",
       "0      Data Science         2\n",
       "1  Machine Learning         3\n",
       "2          Big Data         6\n",
       "3     Data Engineer         4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cacaaa7-c472-451c-b829-8a6f260167ff",
   "metadata": {},
   "source": [
    "# Q2. What is the difference between the functions loc and iloc in pandas.DataFrame?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10c6077-a746-4d0e-ac5c-1115a93fe1fe",
   "metadata": {},
   "source": [
    "In pandas, loc and iloc are both used for accessing data within a DataFrame, but they differ in the way they index data.\n",
    "\n",
    "iloc (Integer Location):\n",
    "\n",
    "iloc is primarily integer-based indexing. It is used when you want to access data by its numerical index.\n",
    "You provide the row and column indices as integers.\n",
    "Example: df.iloc[1, 0] would give you the element in the second row and the first column.\n",
    "loc (Label-based Location):\n",
    "\n",
    "loc is label-based indexing. It is used when you want to access data using the labels of rows or columns.\n",
    "You provide the row and column labels (or boolean arrays).\n",
    "Example: df.loc[1, 'course_name'] would give you the element in the row with label 1 and column with label 'course_name'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eadf1bba-39ac-4959-91a9-309ca4f0a3e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "course_name    Machine Learning\n",
      "duration                      3\n",
      "Name: 1, dtype: object\n",
      "Machine Learning\n"
     ]
    }
   ],
   "source": [
    "# Using iloc\n",
    "print(df.iloc[1])          # Access the second row\n",
    "\n",
    "# Using loc\n",
    "print(df.loc[1, 'course_name'])   # Access the 'course_name' value in the row with label 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2266270-20e7-4ddb-95ad-1e82e03a5585",
   "metadata": {},
   "source": [
    "## Q3. Reindex the given dataframe using a variable, reindex = [3,0,1,2] and store it in the variable, new_df\n",
    "then find the output for both new_df.loc[2] and new_df.iloc[2].\n",
    "Did you observe any difference in both the outputs? If so then explain it.\n",
    "Consider the below code to answer further questions:\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "columns = ['column_1', 'column_2', 'column_3', 'column_4', 'column_5', 'column_6']\n",
    "indices = [1,2,3,4,5,6]\n",
    "#Creating a dataframe:\n",
    "df1 = pd.DataFrame(np.random.rand(6,6), columns = columns, index = indices)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d827da72-c282-4762-a1b4-73f76e17a6fc",
   "metadata": {},
   "source": [
    "\n",
    "### Certainly! You can reindex the DataFrame using the reindex method and then use loc and iloc accordingly. Here's the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60a32136-ebfa-4eb6-a4b6-8697584e42c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reindexed DataFrame:\n",
      "   column_1  column_2  column_3  column_4  column_5  column_6\n",
      "3  0.443848  0.618011  0.636043  0.896141  0.623497  0.162495\n",
      "0       NaN       NaN       NaN       NaN       NaN       NaN\n",
      "1  0.775001  0.398793  0.479550  0.417825  0.266501  0.668329\n",
      "2  0.750581  0.259794  0.902637  0.468581  0.927630  0.176880\n",
      "\n",
      "Output for new_df.loc[2]:\n",
      "column_1    0.750581\n",
      "column_2    0.259794\n",
      "column_3    0.902637\n",
      "column_4    0.468581\n",
      "column_5    0.927630\n",
      "column_6    0.176880\n",
      "Name: 2, dtype: float64\n",
      "\n",
      "Output for new_df.iloc[2]:\n",
      "column_1    0.775001\n",
      "column_2    0.398793\n",
      "column_3    0.479550\n",
      "column_4    0.417825\n",
      "column_5    0.266501\n",
      "column_6    0.668329\n",
      "Name: 1, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Given DataFrame\n",
    "columns = ['column_1', 'column_2', 'column_3', 'column_4', 'column_5', 'column_6']\n",
    "indices = [1, 2, 3, 4, 5, 6]\n",
    "df1 = pd.DataFrame(np.random.rand(6, 6), columns=columns, index=indices)\n",
    "\n",
    "# Define the new index order\n",
    "reindex_order = [3, 0, 1, 2]\n",
    "\n",
    "# Reindex the DataFrame\n",
    "new_df = df1.reindex(reindex_order)\n",
    "\n",
    "# Display the new DataFrame\n",
    "print(\"Reindexed DataFrame:\")\n",
    "print(new_df)\n",
    "\n",
    "# Accessing data using loc and iloc\n",
    "print(\"\\nOutput for new_df.loc[2]:\")\n",
    "print(new_df.loc[2])\n",
    "\n",
    "print(\"\\nOutput for new_df.iloc[2]:\")\n",
    "print(new_df.iloc[2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e9f002-d401-4226-b487-3e58ea3a93ac",
   "metadata": {},
   "source": [
    "Observations:\n",
    "\n",
    "For new_df.loc[2], the output corresponds to the row with the label '2' in the reindexed DataFrame.\n",
    "For new_df.iloc[2], the output corresponds to the row at the numerical index 2 in the reindexed DataFrame.\n",
    "In this case, since the DataFrame was reindexed, the row with the label '2' is now in the third position after reindexing. As a result, new_df.loc[2] and new_df.iloc[2] do not refer to the same row in the reindexed DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49051cad-23e1-40d6-b951-fd4ce2b611c5",
   "metadata": {},
   "source": [
    "## Q4. Write a code to find the following statistical measurements for the above dataframe df1:\n",
    "(i) mean of each and every column present in the dataframe.\n",
    "(ii) standard deviation of column, ‘column_2’"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1720ccf0-4729-4001-b70e-a3198b0d4c91",
   "metadata": {},
   "source": [
    "Certainly! You can use the mean and std methods of the DataFrame to calculate the mean and standard deviation, respectively. Here's the code for the statistical measurements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b09ed374-e171-4c8e-aa69-022b5c8a8bbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of each column:\n",
      "column_1    0.424843\n",
      "column_2    0.504696\n",
      "column_3    0.520966\n",
      "column_4    0.490894\n",
      "column_5    0.548278\n",
      "column_6    0.471142\n",
      "dtype: float64\n",
      "\n",
      "Standard deviation of 'column_2': 0.34393923924129494\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Given DataFrame\n",
    "columns = ['column_1', 'column_2', 'column_3', 'column_4', 'column_5', 'column_6']\n",
    "indices = [1, 2, 3, 4, 5, 6]\n",
    "df1 = pd.DataFrame(np.random.rand(6, 6), columns=columns, index=indices)\n",
    "\n",
    "# (i) Mean of each column\n",
    "column_means = df1.mean()\n",
    "print(\"Mean of each column:\")\n",
    "print(column_means)\n",
    "\n",
    "# (ii) Standard deviation of column 'column_2'\n",
    "std_column_2 = df1['column_2'].std()\n",
    "print(\"\\nStandard deviation of 'column_2':\", std_column_2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3491d1ac-d377-40bf-933a-57e1ca155d10",
   "metadata": {},
   "source": [
    "(i) calculates the mean of each column using df1.mean().\n",
    "(ii) calculates the standard deviation of 'column_2' using df1['column_2'].std()."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3737d1-65c5-48b6-a380-188e33ba0e8c",
   "metadata": {},
   "source": [
    "## Q5. Replace the data present in the second row of column, ‘column_2’ by a string variable then find the mean of column, column_2. If you are getting errors in executing it then explain why.\n",
    "[Hint: To replace the data use df1.loc[] and equate this to string data of your choice.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ac5c750-a655-4d42-9e88-92f2f2d6efca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated DataFrame:\n",
      "   column_1       column_2  column_3  column_4  column_5  column_6\n",
      "1  0.008700       0.244766  0.495597  0.096434  0.525484  0.418965\n",
      "2  0.300338  NewStringData  0.878816  0.147410  0.508009  0.005633\n",
      "3  0.925513       0.289007  0.441394  0.876719  0.159773  0.463105\n",
      "4  0.041210       0.866588  0.459734  0.296975  0.438680  0.510205\n",
      "5  0.978656       0.359425  0.495382  0.336214  0.035595  0.348693\n",
      "6  0.206028       0.393708  0.237481  0.997645  0.417992  0.615503\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'float' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(df1)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Calculate the mean of 'column_2'\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m mean_column_2 \u001b[38;5;241m=\u001b[39m \u001b[43mdf1\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcolumn_2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mMean of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolumn_2\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m after replacement:\u001b[39m\u001b[38;5;124m\"\u001b[39m, mean_column_2)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/generic.py:11847\u001b[0m, in \u001b[0;36mNDFrame._add_numeric_operations.<locals>.mean\u001b[0;34m(self, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11829\u001b[0m \u001b[38;5;129m@doc\u001b[39m(\n\u001b[1;32m  11830\u001b[0m     _num_doc,\n\u001b[1;32m  11831\u001b[0m     desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturn the mean of the values over the requested axis.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  11845\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m  11846\u001b[0m ):\n\u001b[0;32m> 11847\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mNDFrame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/generic.py:11401\u001b[0m, in \u001b[0;36mNDFrame.mean\u001b[0;34m(self, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11393\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmean\u001b[39m(\n\u001b[1;32m  11394\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  11395\u001b[0m     axis: Axis \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m lib\u001b[38;5;241m.\u001b[39mNoDefault \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mno_default,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  11399\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m  11400\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[0;32m> 11401\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stat_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m  11402\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmean\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnanops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnanmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m  11403\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/generic.py:11353\u001b[0m, in \u001b[0;36mNDFrame._stat_function\u001b[0;34m(self, name, func, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11343\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m  11344\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing the level keyword in DataFrame and Series aggregations is \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m  11345\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeprecated and will be removed in a future version. Use groupby \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  11348\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m  11349\u001b[0m     )\n\u001b[1;32m  11350\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agg_by_level(\n\u001b[1;32m  11351\u001b[0m         name, axis\u001b[38;5;241m=\u001b[39maxis, level\u001b[38;5;241m=\u001b[39mlevel, skipna\u001b[38;5;241m=\u001b[39mskipna, numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only\n\u001b[1;32m  11352\u001b[0m     )\n\u001b[0;32m> 11353\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reduce\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m  11354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_only\u001b[49m\n\u001b[1;32m  11355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/series.py:4816\u001b[0m, in \u001b[0;36mSeries._reduce\u001b[0;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[1;32m   4812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m   4813\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSeries.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not implement \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwd_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4814\u001b[0m     )\n\u001b[1;32m   4815\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 4816\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelegate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:93\u001b[0m, in \u001b[0;36mdisallow.__call__.<locals>._f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(invalid\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 93\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;66;03m# we want to transform an object array\u001b[39;00m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;66;03m# ValueError message to the more typical TypeError\u001b[39;00m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;66;03m# e.g. this is normally a disallowed function on\u001b[39;00m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;66;03m# object arrays that contain strings\u001b[39;00m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_object_dtype(args[\u001b[38;5;241m0\u001b[39m]):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:155\u001b[0m, in \u001b[0;36mbottleneck_switch.__call__.<locals>.f\u001b[0;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[1;32m    153\u001b[0m         result \u001b[38;5;241m=\u001b[39m alt(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 155\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43malt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:418\u001b[0m, in \u001b[0;36m_datetimelike_compat.<locals>.new_func\u001b[0;34m(values, axis, skipna, mask, **kwargs)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike \u001b[38;5;129;01mand\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    416\u001b[0m     mask \u001b[38;5;241m=\u001b[39m isna(values)\n\u001b[0;32m--> 418\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike:\n\u001b[1;32m    421\u001b[0m     result \u001b[38;5;241m=\u001b[39m _wrap_results(result, orig_values\u001b[38;5;241m.\u001b[39mdtype, fill_value\u001b[38;5;241m=\u001b[39miNaT)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:706\u001b[0m, in \u001b[0;36mnanmean\u001b[0;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[1;32m    703\u001b[0m     dtype_count \u001b[38;5;241m=\u001b[39m dtype\n\u001b[1;32m    705\u001b[0m count \u001b[38;5;241m=\u001b[39m _get_counts(values\u001b[38;5;241m.\u001b[39mshape, mask, axis, dtype\u001b[38;5;241m=\u001b[39mdtype_count)\n\u001b[0;32m--> 706\u001b[0m the_sum \u001b[38;5;241m=\u001b[39m _ensure_numeric(\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_sum\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    708\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(the_sum, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    709\u001b[0m     count \u001b[38;5;241m=\u001b[39m cast(np\u001b[38;5;241m.\u001b[39mndarray, count)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:48\u001b[0m, in \u001b[0;36m_sum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sum\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     47\u001b[0m          initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m---> 48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mumr_sum\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'float' and 'str'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Given DataFrame\n",
    "columns = ['column_1', 'column_2', 'column_3', 'column_4', 'column_5', 'column_6']\n",
    "indices = [1, 2, 3, 4, 5, 6]\n",
    "df1 = pd.DataFrame(np.random.rand(6, 6), columns=columns, index=indices)\n",
    "\n",
    "# Replace the data in the second row of 'column_2' with a string variable\n",
    "replacement_value = \"NewStringData\"\n",
    "df1.loc[2, 'column_2'] = replacement_value\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(\"Updated DataFrame:\")\n",
    "print(df1)\n",
    "\n",
    "# Calculate the mean of 'column_2'\n",
    "mean_column_2 = df1['column_2'].mean()\n",
    "print(\"\\nMean of 'column_2' after replacement:\", mean_column_2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a8b3dc-73ce-4b51-bf75-4fc7e479256d",
   "metadata": {},
   "source": [
    "However, there might be an issue with calculating the mean after replacing a numerical column with a string. If there is a mix of numerical and non-numerical data in the column, the mean will be represented as nan (Not a Number). It's generally not meaningful to calculate the mean of a column containing string values along with numerical values. If you want to work with numerical data, consider replacing the string with a numerical value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e0808c-1d55-4765-a025-dec9f882809d",
   "metadata": {},
   "source": [
    "## Q6. What do you understand about the windows function in pandas and list the types of windows functions?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55f0677-1ed0-42b2-84ef-114642d81106",
   "metadata": {},
   "source": [
    "In pandas, the term \"window functions\" typically refers to operations performed on a set of data points within a specified window, such as a moving average, cumulative sum, or rolling calculations. These functions are often used in time-series analysis or data smoothing to understand trends and patterns in the data.\n",
    "\n",
    "Window functions in pandas are primarily implemented using the rolling method, which creates a \"rolling view\" on the data. This rolling view allows you to perform various computations over a specified window of data points.\n",
    "\n",
    "Here are some common types of window functions in pandas:\n",
    "\n",
    "Rolling Mean:\n",
    "\n",
    "Computes the mean of a specified window of values as it moves through the data.\n",
    "Example: df['column'].rolling(window=3).mean() calculates the rolling mean with a window size of 3.\n",
    "Rolling Sum:\n",
    "\n",
    "Computes the sum of a specified window of values as it moves through the data.\n",
    "Example: df['column'].rolling(window=4).sum() calculates the rolling sum with a window size of 4.\n",
    "Rolling Standard Deviation:\n",
    "\n",
    "Computes the standard deviation of a specified window of values as it moves through the data.\n",
    "Example: df['column'].rolling(window=5).std() calculates the rolling standard deviation with a window size of 5.\n",
    "Exponential Moving Average (EMA):\n",
    "\n",
    "Computes a weighted moving average, giving more weight to recent observations.\n",
    "Example: df['column'].ewm(span=3, adjust=False).mean() calculates the exponential moving average with a span of 3.\n",
    "Expanding Windows:\n",
    "\n",
    "Computes statistics over all preceding values in the series.\n",
    "Example: df['column'].expanding().sum() calculates the cumulative sum of all values seen so far.\n",
    "Custom Window Functions:\n",
    "\n",
    "You can define and apply custom functions using rolling().apply() or expanding().apply()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "822cd53c-8057-4fe3-8a74-74bb86e30deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "     values\n",
      "0  0.819731\n",
      "1  0.801032\n",
      "2  0.879873\n",
      "3  0.205829\n",
      "4  0.234807\n",
      "5  0.059530\n",
      "6  0.279765\n",
      "7  0.229587\n",
      "8  0.062584\n",
      "9  0.748787\n",
      "\n",
      "Rolling Mean:\n",
      "0         NaN\n",
      "1         NaN\n",
      "2    0.833545\n",
      "3    0.628911\n",
      "4    0.440170\n",
      "5    0.166722\n",
      "6    0.191367\n",
      "7    0.189627\n",
      "8    0.190645\n",
      "9    0.346986\n",
      "Name: values, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create a sample DataFrame\n",
    "data = {'values': np.random.rand(10)}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Calculate the rolling mean with a window size of 3\n",
    "rolling_mean = df['values'].rolling(window=3).mean()\n",
    "\n",
    "# Display the results\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "print(\"\\nRolling Mean:\")\n",
    "print(rolling_mean)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8095a01-4337-4331-9cae-ae21ff9fba67",
   "metadata": {},
   "source": [
    "In this example, rolling_mean calculates the rolling mean of the 'values' column with a window size of 3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cee94bd-1e6e-4519-853f-44fe7b67b749",
   "metadata": {},
   "source": [
    "## Q7. Write a code to print only the current month and year at the time of answering this question.\n",
    "[Hint: Use pandas.datetime function]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9fd4fced-5933-4dcb-9d26-53df881360b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Month: 2\n",
      "Current Year: 2024\n"
     ]
    }
   ],
   "source": [
    "# Get the current date and time\n",
    "current_date = pd.Timestamp.now()\n",
    "\n",
    "# Extract the current month and year\n",
    "current_month = current_date.month\n",
    "current_year = current_date.year\n",
    "\n",
    "# Print the results\n",
    "print(\"Current Month:\", current_month)\n",
    "print(\"Current Year:\", current_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee63cfb-5b72-46d0-9bb8-665beef97b1f",
   "metadata": {},
   "source": [
    "This code will output the current month and year at the time of execution. Note that the pd.Timestamp.now() function provides the current date and time, and we extract the month and year from it.\n",
    "\n",
    "Keep in mind that the result will be based on the system's local time zone where the code is executed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb666c9-1d14-4268-8f30-14eb3157507d",
   "metadata": {},
   "source": [
    "## Q8. Write a Python program that takes in two dates as input (in the format YYYY-MM-DD) and calculates the difference between them in days, hours, and minutes using Pandas time delta. The program should prompt the user to enter the dates and display the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c45189e-36ee-4297-8b0b-031a3411e57f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the start date (YYYY-MM-DD):  1997-07-09\n",
      "Enter the end date (YYYY-MM-DD):  2024-02-22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time Difference:\n",
      "Days: 9724 days\n",
      "Hours: 0 hours\n",
      "Minutes: 0 minutes\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function to calculate the difference between two dates\n",
    "def calculate_time_difference(start_date, end_date):\n",
    "    # Convert input strings to Pandas Timestamp\n",
    "    start_timestamp = pd.to_datetime(start_date)\n",
    "    end_timestamp = pd.to_datetime(end_date)\n",
    "\n",
    "    # Calculate time difference\n",
    "    time_difference = end_timestamp - start_timestamp\n",
    "\n",
    "    # Extract days, hours, and minutes\n",
    "    days = time_difference.days\n",
    "    hours, remainder = divmod(time_difference.seconds, 3600)\n",
    "    minutes, _ = divmod(remainder, 60)\n",
    "\n",
    "    return days, hours, minutes\n",
    "\n",
    "# Get user input for two dates\n",
    "start_date_input = input(\"Enter the start date (YYYY-MM-DD): \")\n",
    "end_date_input = input(\"Enter the end date (YYYY-MM-DD): \")\n",
    "\n",
    "# Calculate time difference\n",
    "try:\n",
    "    days, hours, minutes = calculate_time_difference(start_date_input, end_date_input)\n",
    "\n",
    "    # Display the result\n",
    "    print(\"\\nTime Difference:\")\n",
    "    print(f\"Days: {days} days\")\n",
    "    print(f\"Hours: {hours} hours\")\n",
    "    print(f\"Minutes: {minutes} minutes\")\n",
    "\n",
    "except ValueError as e:\n",
    "    print(f\"Error: {e}. Please enter dates in the correct format (YYYY-MM-DD).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a2a4ea-c5da-413a-a54f-ce8d5b4477de",
   "metadata": {},
   "source": [
    "## Q9. Write a Python program that reads a CSV file containing categorical data and converts a specified column to a categorical data type. The program should prompt the user to enter the file path, column name, and category order, and then display the sorted data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "149f855c-2711-47cc-bac7-1f98a55d2384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the CSV file path:  work/WEEK 8/assignment/titanic.csv\n",
      "Enter the column name to convert to categorical:  Survived\n",
      "Enter the category order (comma-separated):  pclass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: File not found at 'work/WEEK 8/assignment/titanic.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function to convert a specified column to categorical data type\n",
    "def convert_to_categorical(file_path, column_name, category_order):\n",
    "    # Read the CSV file\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at '{file_path}'.\")\n",
    "        return\n",
    "\n",
    "    # Convert the specified column to categorical with specified order\n",
    "    try:\n",
    "        df[column_name] = pd.Categorical(df[column_name], categories=category_order, ordered=True)\n",
    "    except KeyError:\n",
    "        print(f\"Error: Column '{column_name}' not found in the DataFrame.\")\n",
    "        return\n",
    "\n",
    "    # Display the sorted data\n",
    "    sorted_df = df.sort_values(by=column_name)\n",
    "    print(\"\\nSorted Data:\")\n",
    "    print(sorted_df)\n",
    "\n",
    "# Get user input for file path, column name, and category order\n",
    "file_path = input(\"Enter the CSV file path: \")\n",
    "column_name = input(\"Enter the column name to convert to categorical: \")\n",
    "category_order = input(\"Enter the category order (comma-separated): \").split(',')\n",
    "\n",
    "# Remove leading and trailing whitespaces from category order\n",
    "category_order = [category.strip() for category in category_order]\n",
    "\n",
    "# Call the function to convert and display the sorted data\n",
    "convert_to_categorical(file_path, column_name, category_order)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4439d34d-69fd-428e-9192-6ba8c9066247",
   "metadata": {},
   "source": [
    "## Q10. Write a Python program that reads a CSV file containing sales data for different products and visualizes the data using a stacked bar chart to show the sales of each product category over time. The program should prompt the user to enter the file path and display the chart.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bd440de2-d54b-4f99-a6b1-2926a56e303b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the CSV file path:  work/WEEK 8/assignment/titanic.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: File not found at 'work/WEEK 8/assignment/titanic.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to visualize sales data using a stacked bar chart\n",
    "def visualize_sales(file_path):\n",
    "    # Read the CSV file\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at '{file_path}'.\")\n",
    "        return\n",
    "\n",
    "    # Ensure the CSV file has the necessary columns (e.g., 'Date', 'Product_Category', 'Sales')\n",
    "    required_columns = ['Date', 'Product_Category', 'Sales']\n",
    "    if not all(column in df.columns for column in required_columns):\n",
    "        print(\"Error: Required columns not found in the DataFrame.\")\n",
    "        return\n",
    "\n",
    "    # Convert 'Date' column to datetime for proper plotting\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "    # Pivot the DataFrame to get a table suitable for plotting\n",
    "    pivot_table = df.pivot(index='Date', columns='Product_Category', values='Sales').fillna(0)\n",
    "\n",
    "    # Plotting a stacked bar chart\n",
    "    pivot_table.plot(kind='bar', stacked=True, figsize=(10, 6))\n",
    "    plt.title('Sales of Each Product Category Over Time')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Sales')\n",
    "    plt.legend(title='Product Category', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "    # Display the chart\n",
    "    plt.show()\n",
    "\n",
    "# Get user input for file path\n",
    "file_path = input(\"Enter the CSV file path: \")\n",
    "\n",
    "# Call the function to visualize and display the chart\n",
    "visualize_sales(file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b96dd8-d51e-4741-9af6-2ced0a7f5240",
   "metadata": {},
   "source": [
    "## Q11. You are given a CSV file containing student data that includes the student ID and their test score. Write\n",
    "a Python program that reads the CSV file, calculates the mean, median, and mode of the test scores, and\n",
    "displays the results in a table.\n",
    "The program should do the followingM\n",
    "I Prompt the user to enter the file path of the CSV file containing the student dataR\n",
    "I Read the CSV file into a Pandas DataFrameR\n",
    "I Calculate the mean, median, and mode of the test scores using Pandas toolsR\n",
    "I Display the mean, median, and mode in a table.\n",
    "Assume the CSV file contains the following columnsM\n",
    "I Student ID: The ID of the studentR\n",
    "I Test Score: The score of the student's test.\n",
    "Example usage of the program:\n",
    "Enter the file path of the CSV file containing the student data: student_data.csv\n",
    "+-----------+--------+\n",
    "| Statistic | Value |\n",
    "+-----------+--------+\n",
    "| Mean | 79.6 |\n",
    "| Median | 82 |\n",
    "| Mode | 85, 90 |\n",
    "+-----------+--------+\n",
    "Assume that the CSV file student_data.csv contains the following data:\n",
    "Student ID,Test Score\n",
    "1,85\n",
    "2,90\n",
    "3,80\n",
    "4,75\n",
    "5,85\n",
    "6,82\n",
    "7,78\n",
    "8,85\n",
    "9,90\n",
    "10,85\n",
    "The program should calculate the mean, median, and mode of the test scores and display the results\n",
    "in a table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d9df0b12-8204-485b-8d36-dbbfae417459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the file path of the CSV file containing the student data:  work/WEEK 8/taxonomy.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: File not found at 'work/WEEK 8/taxonomy.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from statistics import mode\n",
    "\n",
    "# Function to calculate mean, median, and mode of test scores and display results in a table\n",
    "def calculate_statistics(file_path):\n",
    "    # Read the CSV file\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at '{file_path}'.\")\n",
    "        return\n",
    "\n",
    "    # Ensure the CSV file has the necessary columns (e.g., 'Student_ID', 'Test_Score')\n",
    "    required_columns = ['Student_ID', 'Test_Score']\n",
    "    if not all(column in df.columns for column in required_columns):\n",
    "        print(\"Error: Required columns not found in the DataFrame.\")\n",
    "        return\n",
    "\n",
    "    # Calculate mean, median, and mode\n",
    "    mean_score = df['Test_Score'].mean()\n",
    "    median_score = df['Test_Score'].median()\n",
    "    mode_score = mode(df['Test_Score'])\n",
    "\n",
    "    # Create a summary table\n",
    "    summary_table = pd.DataFrame({\n",
    "        'Statistic': ['Mean', 'Median', 'Mode'],\n",
    "        'Value': [mean_score, median_score, mode_score]\n",
    "    })\n",
    "\n",
    "    # Display the results\n",
    "    print(\"\\n+-----------+--------+\")\n",
    "    print(\"| Statistic | Value  |\")\n",
    "    print(\"+-----------+--------+\")\n",
    "    for index, row in summary_table.iterrows():\n",
    "        print(f\"| {row['Statistic']:9} | {row['Value']:6.1f} |\")\n",
    "    print(\"+-----------+--------+\")\n",
    "\n",
    "# Get user input for file path\n",
    "file_path = input(\"Enter the file path of the CSV file containing the student data: \")\n",
    "\n",
    "# Call the function to calculate statistics and display the results\n",
    "calculate_statistics(file_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1571f707-797c-4424-b117-b5121a02111a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
